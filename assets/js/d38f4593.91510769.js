"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[698],{3905:function(e,n,t){t.d(n,{Zo:function(){return p},kt:function(){return d}});var a=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var c=a.createContext({}),l=function(e){var n=a.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},p=function(e){var n=l(e.components);return a.createElement(c.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},h=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,i=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),h=l(t),d=o,m=h["".concat(c,".").concat(d)]||h[d]||u[d]||i;return t?a.createElement(m,r(r({ref:n},p),{},{components:t})):a.createElement(m,r({ref:n},p))}));function d(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var i=t.length,r=new Array(i);r[0]=h;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var l=2;l<i;l++)r[l]=t[l];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}h.displayName="MDXCreateElement"},2801:function(e,n,t){t.r(n),t.d(n,{assets:function(){return p},contentTitle:function(){return c},default:function(){return d},frontMatter:function(){return s},metadata:function(){return l},toc:function(){return u}});var a=t(7462),o=t(3366),i=(t(7294),t(3905)),r=["components"],s={id:"computation-caching",title:"Computation Caching"},c="Computation Caching",l={unversionedId:"core-concepts/computation-caching",id:"core-concepts/computation-caching",title:"Computation Caching",description:'When it comes to running tasks, caching etc., Lerna and Nx can be used interchangeably. When we say "Lerna can cache',source:"@site/docs/core-concepts/caching.md",sourceDirName:"core-concepts",slug:"/core-concepts/computation-caching",permalink:"/docs/core-concepts/computation-caching",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/core-concepts/caching.md",tags:[],version:"current",frontMatter:{id:"computation-caching",title:"Computation Caching"},sidebar:"main",previous:{title:"Versioning and Publishing",permalink:"/docs/core-concepts/versioning-and-publishing"},next:{title:"Distributed Task Execution",permalink:"/docs/core-concepts/distributed-task-execution"}},p={},u=[{value:"Source Code Hash Inputs",id:"source-code-hash-inputs",level:2},{value:"Runtime Hash Inputs",id:"runtime-hash-inputs",level:2},{value:"Args Hash Inputs",id:"args-hash-inputs",level:2},{value:"What is Cached",id:"what-is-cached",level:2},{value:"Skipping Cache",id:"skipping-cache",level:2},{value:"Customizing the Cache Location",id:"customizing-the-cache-location",level:2},{value:"Local Computation Caching",id:"local-computation-caching",level:2},{value:"Distributed Computation Caching",id:"distributed-computation-caching",level:2}],h={toc:u};function d(e){var n=e.components,s=(0,o.Z)(e,r);return(0,i.kt)("wrapper",(0,a.Z)({},h,s,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"computation-caching"},"Computation Caching"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},'When it comes to running tasks, caching etc., Lerna and Nx can be used interchangeably. When we say "Lerna can cache\nbuilds", we mean that Lerna uses Nx which can cache builds.')),(0,i.kt)("p",null,"It's costly to rebuild and retest the same code over and over again. Lerna uses a computation cache to never rebuild the\nsame code twice. This is how it does it."),(0,i.kt)("p",null,"Before running any task, Lerna computes its computation hash. As long as the computation hash is the same, the output of\nrunning the task is the same."),(0,i.kt)("p",null,"By default, the computation hash for - say - ",(0,i.kt)("inlineCode",{parentName:"p"},"lerna run test --scope=remixapp")," includes:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"All the source files of ",(0,i.kt)("inlineCode",{parentName:"li"},"remixapp")," and its dependencies"),(0,i.kt)("li",{parentName:"ul"},"Relevant global configuration"),(0,i.kt)("li",{parentName:"ul"},"Versions of external dependencies"),(0,i.kt)("li",{parentName:"ul"},"Runtime values provisioned by the user such as the version of Node"),(0,i.kt)("li",{parentName:"ul"},"CLI Command flags")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"computation-hashing",src:t(3238).Z,width:"2088",height:"1580"})),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"This behavior is customizable. For instance, lint checks may only depend on the source code of the project and global\nconfigs. Builds can depend on the dts files of the compiled libs instead of their source.")),(0,i.kt)("p",null,"After Lerna computes the hash for a task, it then checks if it ran this exact computation before. First, it checks\nlocally, and then if it is missing, and if a remote cache is configured, it checks remotely."),(0,i.kt)("p",null,"If Lerna finds the computation, Lerna retrieves it and replays it. Lerna places the right files in the right folders and\nprints the terminal output. From the user\u2019s point of view, the command ran the same, just a lot faster."),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"cache",src:t(4710).Z,width:"826",height:"522"})),(0,i.kt)("p",null,"If Lerna doesn\u2019t find a corresponding computation hash, Lerna runs the task, and after it completes, it takes the\noutputs and the terminal logs and stores them locally (and if configured remotely as well). All of this happens\ntransparently, so you don\u2019t have to worry about it."),(0,i.kt)("p",null,"Although conceptually this is fairly straightforward, Lerna optimizes this to make this experience good for you. For\ninstance, Lerna:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Captures stdout and stderr to make sure the replayed output looks the same, including on Windows."),(0,i.kt)("li",{parentName:"ul"},"Minimizes the IO by remembering what files are replayed where."),(0,i.kt)("li",{parentName:"ul"},"Only shows relevant output when processing a large task graph."),(0,i.kt)("li",{parentName:"ul"},"Provides affordances for troubleshooting cache misses. And many other optimizations.")),(0,i.kt)("p",null,"As your workspace grows, the task graph looks more like this:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"cache",src:t(2681).Z,width:"488",height:"467"})),(0,i.kt)("p",null,"All of these optimizations are crucial for making Lerna usable for any non-trivial workspace. Only the minimum amount of\nwork happens. The rest is either left as is or restored from the cache."),(0,i.kt)("h2",{id:"source-code-hash-inputs"},"Source Code Hash Inputs"),(0,i.kt)("p",null,"The result of building/testing an application or a library depends on the source code of that project and all the source\ncodes of all the libraries it depends on (directly or indirectly). It also depends on the configuration files\nlike ",(0,i.kt)("inlineCode",{parentName:"p"},"package.json"),", ",(0,i.kt)("inlineCode",{parentName:"p"},"nx.json"),", and ",(0,i.kt)("inlineCode",{parentName:"p"},"package-lock.json"),". The list of these files isn't arbitrary."),(0,i.kt)("p",null,"Lerna can deduce most of them by analyzing the codebase. If there are exceptions that cannot be inferred automatically,\nthey can be manually listed in the ",(0,i.kt)("inlineCode",{parentName:"p"},"implicitDependencies")," property of ",(0,i.kt)("inlineCode",{parentName:"p"},"nx.json"),"."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "implicitDependencies": {\n    "global-config-file.json": "*"\n  },\n  ...\n}\n')),(0,i.kt)("h2",{id:"runtime-hash-inputs"},"Runtime Hash Inputs"),(0,i.kt)("p",null,"All commands listed in ",(0,i.kt)("inlineCode",{parentName:"p"},"runtimeCacheInputs")," are invoked by Lerna, and the results are included in the computation hash\nof each task. You can customize them in ",(0,i.kt)("inlineCode",{parentName:"p"},"nx.json"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tasksRunnerOptions": {\n    "default": {\n      "options": {\n        "cacheableOperations": [\n          "build",\n          "test"\n        ],\n        "runtimeCacheInputs": [\n          "node -v",\n          "echo $IMPORTANT_ENV_VAR"\n        ]\n      }\n    }\n  }\n}\n')),(0,i.kt)("p",null,"Sometimes the amount of ",(0,i.kt)("em",{parentName:"p"},"runtimeCacheInputs")," can be too overwhelming and difficult to read or parse. In this case, we\nrecommend creating a ",(0,i.kt)("inlineCode",{parentName:"p"},"SHA")," from those inputs. It can be done as follows:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tasksRunnerOptions": {\n    "default": {\n      "options": {\n        "cacheableOperations": [\n          "build",\n          "test"\n        ],\n        "runtimeCacheInputs": [\n          "node -v",\n          "echo $IMPORTANT_ENV_VAR",\n          "echo $LONG_IMPORTANT_ENV_VAR | sha256sum",\n          "cat path/to/my/big-list-of-checksums.txt | sha256sum"\n        ]\n      }\n    }\n  }\n}\n')),(0,i.kt)("h2",{id:"args-hash-inputs"},"Args Hash Inputs"),(0,i.kt)("p",null,"Finally, in addition to Source Code Hash Inputs and Runtime Hash Inputs, Lerna needs to consider the arguments: For\nexample, ",(0,i.kt)("inlineCode",{parentName:"p"},"lerna run build --scope=remixapp")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"lerna run build --scope=remixapp -- --flag=true")," produce different\nresults."),(0,i.kt)("p",null,"Note, only the flags passed to the npm scripts itself affect results of the computation. For instance, the following\ncommands are identical from the caching perspective."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"> npx lerna run build --scope=remixapp\n> npx lerna run build --ignore=header,footer\n")),(0,i.kt)("p",null,"In other words, Lerna does not cache what the developer types into the terminal."),(0,i.kt)("p",null,"If you build/test/lint\u2026 multiple projects, each individual build has its own hash value and will either be retrieved from\ncache or run. This means that from the caching point of view, the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"> npx lerna run build --scope=header,footer\n")),(0,i.kt)("p",null,"is identical to the following two commands:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"> npx lerna run build --scope=header\n> npx lerna run build --scope=footer\n")),(0,i.kt)("h2",{id:"what-is-cached"},"What is Cached"),(0,i.kt)("p",null,"Lerna works on the process level. Regardless of the tools used to build/test/lint/etc.. your project, the results are\ncached."),(0,i.kt)("p",null,"Lerna sets up hooks to collect stdout/stderr before running the command. All the output is cached and then replayed\nduring a cache hit."),(0,i.kt)("p",null,"Lerna also caches the files generated by a command. The list of files/folders is listed in the ",(0,i.kt)("inlineCode",{parentName:"p"},"outputs")," property of the\nproject's ",(0,i.kt)("inlineCode",{parentName:"p"},"package.json"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "nx": {\n    "targets": {\n      "build": {\n        "outputs": [\n          "./build",\n          "./public/build"\n        ]\n      }\n    }\n  }\n}\n')),(0,i.kt)("p",null,"If the ",(0,i.kt)("inlineCode",{parentName:"p"},"outputs")," property for a given target isn't defined in the project'\ns ",(0,i.kt)("inlineCode",{parentName:"p"},"package.json")," file, Lerna will look at the ",(0,i.kt)("inlineCode",{parentName:"p"},"targetDefaults")," section of ",(0,i.kt)("inlineCode",{parentName:"p"},"nx.json"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  ...\n  "targetDefaults": {\n    "build": {\n      "dependsOn": ["^build"],\n      "outputs": [\n        "./dist",\n        "./build",\n        "./public/build"\n      ]\n    }\n  }\n}\n')),(0,i.kt)("p",null,"If neither is defined, Lerna defaults to caching ",(0,i.kt)("inlineCode",{parentName:"p"},"dist")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"build")," at the root of the repository."),(0,i.kt)("h2",{id:"skipping-cache"},"Skipping Cache"),(0,i.kt)("p",null,"Sometimes you want to skip the cache. If, for example, you are measuring the performance of a command, you can use\nthe ",(0,i.kt)("inlineCode",{parentName:"p"},"--skip-nx-cache")," flag to skip checking the computation cache."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"> npx lerna run build --skip-nx-cache\n> npx lerna run test --skip-nx-cache\n")),(0,i.kt)("h2",{id:"customizing-the-cache-location"},"Customizing the Cache Location"),(0,i.kt)("p",null,"The cache is stored in ",(0,i.kt)("inlineCode",{parentName:"p"},"node_modules/.cache/nx")," by default. To change the cache location, update the ",(0,i.kt)("inlineCode",{parentName:"p"},"cacheDirectory"),"\noption for the task runner in ",(0,i.kt)("inlineCode",{parentName:"p"},"nx.json"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "tasksRunnerOptions": {\n    "default": {\n      "options": {\n        "cacheableOperations": [\n          "build",\n          "test"\n        ],\n        "cacheDirectory": "/tmp/mycache"\n      }\n    }\n  }\n}\n')),(0,i.kt)("h2",{id:"local-computation-caching"},"Local Computation Caching"),(0,i.kt)("p",null,"By default, Lerna (via Nx) uses a local computation cache. Nx stores the cached values only for a week, after which they\nare deleted. To clear the cache run ",(0,i.kt)("inlineCode",{parentName:"p"},"nx reset"),", and Nx will create a new one the next time it tries to access it."),(0,i.kt)("h2",{id:"distributed-computation-caching"},"Distributed Computation Caching"),(0,i.kt)("p",null,"The computation cache provided by Nx can be distributed across multiple machines. You can either build an implementation\nof the cache or use Nx Cloud. Nx Cloud is an app that provides a fast and zero-config implementation of distributed\ncaching. It's completely free for OSS projects and for most closed-sourced\nprojects (",(0,i.kt)("a",{parentName:"p",href:"https://dev.to/nrwl/more-time-saved-for-free-with-nx-cloud-4a2j"},"read more here"),")."),(0,i.kt)("p",null,"You can connect your workspace to Nx Cloud by running:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"> npx nx connect-to-nx-cloud\n")),(0,i.kt)("p",null,"Learn more about Nx Cloud at ",(0,i.kt)("a",{parentName:"p",href:"https://nx.app"},"https://nx.app"),"."))}d.isMDXComponent=!0},4710:function(e,n,t){n.Z=t.p+"assets/images/cache-c67f30b99d684071f4f042509a39448e.png"},3238:function(e,n,t){n.Z=t.p+"assets/images/lerna-hashing-d90a81e4acb3c97217f66a22f7b8c745.png"},2681:function(e,n,t){n.Z=t.p+"assets/images/task-graph-big-c67fec16567b185ddeed8e7433aad868.png"}}]);